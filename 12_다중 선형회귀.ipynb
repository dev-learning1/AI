{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12_다중 선형회귀.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOaQFeuPoaBYy4wwNO+RDf4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"lWHKPJQ9-Opw","executionInfo":{"status":"ok","timestamp":1653049748649,"user_tz":-540,"elapsed":9,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"696a91ee-6fdd-4d02-edf1-3f7cf64bbb63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n공부한시간        2   2   2   3   4   4\\n학원 공부한 시간  0   1   2   1   1   2\\n과외 시간         0   0   1   1   2   2\\n실제 값           50  60  65  70  75  85\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# 공부한 시간, 학원에서 공부한 시간, 과외 시간, 점수\n","'''\n","공부한시간        2   2   2   3   4   4\n","학원 공부한 시간  0   1   2   1   1   2\n","과외 시간         0   0   1   1   2   2\n","실제 값           50  60  65  70  75  85\n","'''\n","# 일반 선형 회귀 : H = wx + b\n","# 다중 선형 회귀 : H = w1x1 + w2x2 + w3x3 + b"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"r8Wu1kycAXHg","executionInfo":{"status":"ok","timestamp":1653049753220,"user_tz":-540,"elapsed":4577,"user":{"displayName":"도희정","userId":"17231039936474573716"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zArMo-K2Aaxj","executionInfo":{"status":"ok","timestamp":1653049753221,"user_tz":-540,"elapsed":10,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"805e8db0-2001-417b-98ec-f0335ddc8dc1"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ff283e947f0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# 시드 예\n","\n","torch.manual_seed(7)\n","print('랜덤 시드 : 7')\n","for i in  range(1,3):\n","  print(torch.rand(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VP95fNurBTAE","executionInfo":{"status":"ok","timestamp":1653049753715,"user_tz":-540,"elapsed":499,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"aa17bab9-1093-4412-bba1-32b89c272ff3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시드 : 7\n","tensor([0.5349])\n","tensor([0.1988])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(9)\n","print('랜덤 시드 : 9')\n","for i in  range(1,3):\n","  print(torch.rand(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GaT7_-yBfJw","executionInfo":{"status":"ok","timestamp":1653049753715,"user_tz":-540,"elapsed":19,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"e3234bea-4378-471b-bfe9-ddcbd9951bbd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시드 : 9\n","tensor([0.6558])\n","tensor([0.3020])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(7)\n","print('랜덤 시드 : 7')\n","for i in  range(1,3):\n","  print(torch.rand(1))\n","\n","  # 같은 시드끼리 랜덤 값 고정"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KtD3qK4BlFg","executionInfo":{"status":"ok","timestamp":1653049753716,"user_tz":-540,"elapsed":8,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"b92f1be8-44db-4f43-d63e-88cb71ca322e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시드 : 7\n","tensor([0.5349])\n","tensor([0.1988])\n"]}]},{"cell_type":"code","source":["x1_train = torch.FloatTensor([[2], [2], [2], [3], [4], [4]])\n","x2_train = torch.FloatTensor([[0], [1], [2], [1], [1], [2]])\n","x3_train = torch.FloatTensor([[0], [0], [1], [1], [2], [2]])\n","y_train = torch.FloatTensor([[50], [60], [65], [70], [75], [85]])"],"metadata":{"id":"Kp8BSP1PAcrG","executionInfo":{"status":"ok","timestamp":1653049753716,"user_tz":-540,"elapsed":6,"user":{"displayName":"도희정","userId":"17231039936474573716"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["w1 = torch.zeros(1, requires_grad=True)\n","w2 = torch.zeros(1, requires_grad=True)\n","w3 = torch.zeros(1, requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)"],"metadata":{"id":"FE795_OgCOCQ","executionInfo":{"status":"ok","timestamp":1653049753716,"user_tz":-540,"elapsed":5,"user":{"displayName":"도희정","userId":"17231039936474573716"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n","tot_epochs = 1000\n","\n","for epoch in range(1, tot_epochs+1):\n","  H = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n","  cost = torch.mean((H-y_train) ** 2)\n","  \n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} w1 : {:.3f}, w2 : {:.3f}, w3 : {:.3f}, b : {:.3f} Cost : {:.6f}'.format(epoch, 2000, w1.item(), w2.item(), w3.item(), b.item(), cost.item()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yh6_7lnQChuz","executionInfo":{"status":"ok","timestamp":1653049754816,"user_tz":-540,"elapsed":1105,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"154d9867-b48a-43ac-e26a-af8d8c778d0f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch  100/2000 w1 : 0.395, w2 : 0.166, w3 : 0.150, b : 0.133 Cost : 4457.451660\n","Epoch  200/2000 w1 : 0.780, w2 : 0.328, w3 : 0.295, b : 0.264 Cost : 4244.458496\n","Epoch  300/2000 w1 : 1.156, w2 : 0.487, w3 : 0.437, b : 0.391 Cost : 4041.941406\n","Epoch  400/2000 w1 : 1.522, w2 : 0.641, w3 : 0.575, b : 0.515 Cost : 3849.384766\n","Epoch  500/2000 w1 : 1.879, w2 : 0.792, w3 : 0.709, b : 0.636 Cost : 3666.297852\n","Epoch  600/2000 w1 : 2.228, w2 : 0.938, w3 : 0.840, b : 0.755 Cost : 3492.215576\n","Epoch  700/2000 w1 : 2.567, w2 : 1.082, w3 : 0.967, b : 0.870 Cost : 3326.694092\n","Epoch  800/2000 w1 : 2.899, w2 : 1.221, w3 : 1.091, b : 0.983 Cost : 3169.312500\n","Epoch  900/2000 w1 : 3.222, w2 : 1.358, w3 : 1.212, b : 1.094 Cost : 3019.669189\n","Epoch 1000/2000 w1 : 3.537, w2 : 1.491, w3 : 1.329, b : 1.201 Cost : 2877.384521\n"]}]},{"cell_type":"code","source":["# 변수가 많으면 가설식(H)이 복잡해짐 => dot product 함수 사용"],"metadata":{"id":"4gorvyGCDZcW","executionInfo":{"status":"ok","timestamp":1653049754817,"user_tz":-540,"elapsed":11,"user":{"displayName":"도희정","userId":"17231039936474573716"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 벡터의 내적(Dot Product)를 사용하여 학습\n","x_train = torch.FloatTensor([[2, 0, 0],\n","                             [2, 1, 0],\n","                             [2, 2, 1],\n","                             [3, 1, 1],\n","                             [4, 1, 2],\n","                             [4, 2, 2]])\n","y_train = torch.FloatTensor([[50], [60], [65], [70], [75], [85]])"],"metadata":{"id":"CRpu2XLEzZYg","executionInfo":{"status":"ok","timestamp":1653049754818,"user_tz":-540,"elapsed":10,"user":{"displayName":"도희정","userId":"17231039936474573716"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape)\n","print(y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQAkOKlp03Re","executionInfo":{"status":"ok","timestamp":1653049754818,"user_tz":-540,"elapsed":9,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"7b6a394a-f882-4d71-be78-f18ce622a3bf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 3])\n","torch.Size([6, 1])\n"]}]},{"cell_type":"code","source":["W = torch.zeros((3,1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","\n","optimizer = optim.SGD([W, b], lr=1e-5)\n","\n","epoch_count = 300\n","for epoch in range(epoch_count+1):\n","  H = x_train.matmul(W) + b # matmul : 파이썬 내장함수\n","\n","  cost = torch.mean((H - y_train) ** 2)\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  print('Epoch {:4d}/{} H:{} cost: {:.6f}'.format(\n","      epoch, epoch_count, H.squeeze().detach(), cost.item() #squeeze : 차원 축소, detach : remove와 비슷 하지만 삭제된 것 저장됌\n","  ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXTmTR5s09EW","executionInfo":{"status":"ok","timestamp":1653049756652,"user_tz":-540,"elapsed":1258,"user":{"displayName":"도희정","userId":"17231039936474573716"}},"outputId":"191fa57d-cbcd-4e55-ae72-f22d2639a721"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/300 H:tensor([0., 0., 0., 0., 0., 0.]) cost: 4679.166504\n","Epoch    1/300 H:tensor([0.0093, 0.0110, 0.0142, 0.0166, 0.0221, 0.0237]) cost: 4676.871094\n","Epoch    2/300 H:tensor([0.0187, 0.0221, 0.0285, 0.0331, 0.0441, 0.0475]) cost: 4674.577148\n","Epoch    3/300 H:tensor([0.0280, 0.0331, 0.0427, 0.0496, 0.0662, 0.0712]) cost: 4672.283691\n","Epoch    4/300 H:tensor([0.0374, 0.0441, 0.0569, 0.0662, 0.0882, 0.0950]) cost: 4669.992676\n","Epoch    5/300 H:tensor([0.0467, 0.0551, 0.0711, 0.0827, 0.1103, 0.1187]) cost: 4667.701660\n","Epoch    6/300 H:tensor([0.0561, 0.0662, 0.0853, 0.0992, 0.1323, 0.1424]) cost: 4665.411621\n","Epoch    7/300 H:tensor([0.0654, 0.0772, 0.0996, 0.1158, 0.1543, 0.1661]) cost: 4663.123535\n","Epoch    8/300 H:tensor([0.0747, 0.0882, 0.1138, 0.1323, 0.1764, 0.1898]) cost: 4660.836426\n","Epoch    9/300 H:tensor([0.0841, 0.0992, 0.1280, 0.1488, 0.1984, 0.2135]) cost: 4658.550293\n","Epoch   10/300 H:tensor([0.0934, 0.1102, 0.1422, 0.1653, 0.2204, 0.2372]) cost: 4656.265137\n","Epoch   11/300 H:tensor([0.1027, 0.1212, 0.1564, 0.1818, 0.2424, 0.2609]) cost: 4653.980957\n","Epoch   12/300 H:tensor([0.1120, 0.1322, 0.1706, 0.1983, 0.2644, 0.2846]) cost: 4651.698730\n","Epoch   13/300 H:tensor([0.1214, 0.1432, 0.1848, 0.2148, 0.2864, 0.3083]) cost: 4649.417480\n","Epoch   14/300 H:tensor([0.1307, 0.1542, 0.1989, 0.2313, 0.3084, 0.3320]) cost: 4647.136719\n","Epoch   15/300 H:tensor([0.1400, 0.1652, 0.2131, 0.2478, 0.3304, 0.3556]) cost: 4644.857422\n","Epoch   16/300 H:tensor([0.1493, 0.1762, 0.2273, 0.2643, 0.3524, 0.3793]) cost: 4642.579590\n","Epoch   17/300 H:tensor([0.1586, 0.1872, 0.2415, 0.2808, 0.3744, 0.4029]) cost: 4640.302734\n","Epoch   18/300 H:tensor([0.1679, 0.1982, 0.2557, 0.2973, 0.3963, 0.4266]) cost: 4638.026855\n","Epoch   19/300 H:tensor([0.1773, 0.2092, 0.2698, 0.3137, 0.4183, 0.4502]) cost: 4635.752441\n","Epoch   20/300 H:tensor([0.1866, 0.2201, 0.2840, 0.3302, 0.4403, 0.4739]) cost: 4633.478516\n","Epoch   21/300 H:tensor([0.1959, 0.2311, 0.2981, 0.3467, 0.4622, 0.4975]) cost: 4631.206543\n","Epoch   22/300 H:tensor([0.2052, 0.2421, 0.3123, 0.3631, 0.4842, 0.5211]) cost: 4628.935547\n","Epoch   23/300 H:tensor([0.2145, 0.2531, 0.3265, 0.3796, 0.5061, 0.5447]) cost: 4626.665527\n","Epoch   24/300 H:tensor([0.2238, 0.2640, 0.3406, 0.3961, 0.5281, 0.5683]) cost: 4624.396484\n","Epoch   25/300 H:tensor([0.2331, 0.2750, 0.3548, 0.4125, 0.5500, 0.5920]) cost: 4622.128906\n","Epoch   26/300 H:tensor([0.2423, 0.2860, 0.3689, 0.4289, 0.5719, 0.6156]) cost: 4619.862305\n","Epoch   27/300 H:tensor([0.2516, 0.2969, 0.3830, 0.4454, 0.5938, 0.6391]) cost: 4617.597168\n","Epoch   28/300 H:tensor([0.2609, 0.3079, 0.3972, 0.4618, 0.6158, 0.6627]) cost: 4615.332520\n","Epoch   29/300 H:tensor([0.2702, 0.3189, 0.4113, 0.4783, 0.6377, 0.6863]) cost: 4613.069336\n","Epoch   30/300 H:tensor([0.2795, 0.3298, 0.4254, 0.4947, 0.6596, 0.7099]) cost: 4610.807129\n","Epoch   31/300 H:tensor([0.2888, 0.3408, 0.4396, 0.5111, 0.6815, 0.7335]) cost: 4608.546387\n","Epoch   32/300 H:tensor([0.2980, 0.3517, 0.4537, 0.5275, 0.7034, 0.7570]) cost: 4606.286621\n","Epoch   33/300 H:tensor([0.3073, 0.3626, 0.4678, 0.5440, 0.7253, 0.7806]) cost: 4604.028320\n","Epoch   34/300 H:tensor([0.3166, 0.3736, 0.4819, 0.5604, 0.7471, 0.8041]) cost: 4601.770996\n","Epoch   35/300 H:tensor([0.3259, 0.3845, 0.4960, 0.5768, 0.7690, 0.8277]) cost: 4599.514160\n","Epoch   36/300 H:tensor([0.3351, 0.3955, 0.5101, 0.5932, 0.7909, 0.8512]) cost: 4597.259277\n","Epoch   37/300 H:tensor([0.3444, 0.4064, 0.5243, 0.6096, 0.8128, 0.8748]) cost: 4595.005371\n","Epoch   38/300 H:tensor([0.3537, 0.4173, 0.5384, 0.6260, 0.8346, 0.8983]) cost: 4592.752441\n","Epoch   39/300 H:tensor([0.3629, 0.4283, 0.5525, 0.6424, 0.8565, 0.9218]) cost: 4590.500488\n","Epoch   40/300 H:tensor([0.3722, 0.4392, 0.5665, 0.6588, 0.8783, 0.9453]) cost: 4588.249512\n","Epoch   41/300 H:tensor([0.3814, 0.4501, 0.5806, 0.6751, 0.9002, 0.9688]) cost: 4586.000488\n","Epoch   42/300 H:tensor([0.3907, 0.4610, 0.5947, 0.6915, 0.9220, 0.9923]) cost: 4583.751953\n","Epoch   43/300 H:tensor([0.3999, 0.4720, 0.6088, 0.7079, 0.9438, 1.0158]) cost: 4581.504395\n","Epoch   44/300 H:tensor([0.4092, 0.4829, 0.6229, 0.7243, 0.9657, 1.0393]) cost: 4579.258301\n","Epoch   45/300 H:tensor([0.4184, 0.4938, 0.6370, 0.7406, 0.9875, 1.0628]) cost: 4577.013672\n","Epoch   46/300 H:tensor([0.4277, 0.5047, 0.6510, 0.7570, 1.0093, 1.0863]) cost: 4574.770020\n","Epoch   47/300 H:tensor([0.4369, 0.5156, 0.6651, 0.7734, 1.0311, 1.1098]) cost: 4572.526855\n","Epoch   48/300 H:tensor([0.4462, 0.5265, 0.6792, 0.7897, 1.0529, 1.1333]) cost: 4570.285645\n","Epoch   49/300 H:tensor([0.4554, 0.5374, 0.6932, 0.8061, 1.0747, 1.1567]) cost: 4568.044922\n","Epoch   50/300 H:tensor([0.4646, 0.5483, 0.7073, 0.8224, 1.0965, 1.1802]) cost: 4565.805176\n","Epoch   51/300 H:tensor([0.4739, 0.5592, 0.7214, 0.8388, 1.1183, 1.2036]) cost: 4563.567871\n","Epoch   52/300 H:tensor([0.4831, 0.5701, 0.7354, 0.8551, 1.1401, 1.2271]) cost: 4561.330078\n","Epoch   53/300 H:tensor([0.4923, 0.5810, 0.7495, 0.8714, 1.1619, 1.2505]) cost: 4559.094238\n","Epoch   54/300 H:tensor([0.5016, 0.5919, 0.7635, 0.8878, 1.1836, 1.2739]) cost: 4556.859863\n","Epoch   55/300 H:tensor([0.5108, 0.6028, 0.7775, 0.9041, 1.2054, 1.2974]) cost: 4554.625977\n","Epoch   56/300 H:tensor([0.5200, 0.6136, 0.7916, 0.9204, 1.2272, 1.3208]) cost: 4552.394043\n","Epoch   57/300 H:tensor([0.5292, 0.6245, 0.8056, 0.9367, 1.2489, 1.3442]) cost: 4550.162109\n","Epoch   58/300 H:tensor([0.5385, 0.6354, 0.8196, 0.9530, 1.2707, 1.3676]) cost: 4547.931641\n","Epoch   59/300 H:tensor([0.5477, 0.6463, 0.8337, 0.9693, 1.2924, 1.3910]) cost: 4545.703125\n","Epoch   60/300 H:tensor([0.5569, 0.6571, 0.8477, 0.9857, 1.3142, 1.4144]) cost: 4543.474609\n","Epoch   61/300 H:tensor([0.5661, 0.6680, 0.8617, 1.0020, 1.3359, 1.4378]) cost: 4541.248047\n","Epoch   62/300 H:tensor([0.5753, 0.6789, 0.8757, 1.0183, 1.3576, 1.4612]) cost: 4539.022461\n","Epoch   63/300 H:tensor([0.5845, 0.6897, 0.8897, 1.0345, 1.3793, 1.4846]) cost: 4536.797363\n","Epoch   64/300 H:tensor([0.5937, 0.7006, 0.9037, 1.0508, 1.4011, 1.5080]) cost: 4534.573730\n","Epoch   65/300 H:tensor([0.6029, 0.7115, 0.9178, 1.0671, 1.4228, 1.5313]) cost: 4532.351074\n","Epoch   66/300 H:tensor([0.6121, 0.7223, 0.9318, 1.0834, 1.4445, 1.5547]) cost: 4530.129883\n","Epoch   67/300 H:tensor([0.6213, 0.7332, 0.9458, 1.0997, 1.4662, 1.5780]) cost: 4527.909668\n","Epoch   68/300 H:tensor([0.6305, 0.7440, 0.9597, 1.1159, 1.4879, 1.6014]) cost: 4525.690918\n","Epoch   69/300 H:tensor([0.6397, 0.7549, 0.9737, 1.1322, 1.5096, 1.6247]) cost: 4523.472656\n","Epoch   70/300 H:tensor([0.6489, 0.7657, 0.9877, 1.1485, 1.5313, 1.6481]) cost: 4521.255859\n","Epoch   71/300 H:tensor([0.6581, 0.7766, 1.0017, 1.1647, 1.5529, 1.6714]) cost: 4519.040527\n","Epoch   72/300 H:tensor([0.6673, 0.7874, 1.0157, 1.1810, 1.5746, 1.6947]) cost: 4516.825684\n","Epoch   73/300 H:tensor([0.6764, 0.7982, 1.0297, 1.1973, 1.5963, 1.7181]) cost: 4514.611816\n","Epoch   74/300 H:tensor([0.6856, 0.8091, 1.0436, 1.2135, 1.6179, 1.7414]) cost: 4512.399902\n","Epoch   75/300 H:tensor([0.6948, 0.8199, 1.0576, 1.2297, 1.6396, 1.7647]) cost: 4510.188477\n","Epoch   76/300 H:tensor([0.7040, 0.8307, 1.0716, 1.2460, 1.6612, 1.7880]) cost: 4507.978516\n","Epoch   77/300 H:tensor([0.7132, 0.8416, 1.0855, 1.2622, 1.6829, 1.8113]) cost: 4505.769043\n","Epoch   78/300 H:tensor([0.7223, 0.8524, 1.0995, 1.2785, 1.7045, 1.8346]) cost: 4503.562012\n","Epoch   79/300 H:tensor([0.7315, 0.8632, 1.1135, 1.2947, 1.7262, 1.8579]) cost: 4501.354980\n","Epoch   80/300 H:tensor([0.7407, 0.8740, 1.1274, 1.3109, 1.7478, 1.8811]) cost: 4499.148926\n","Epoch   81/300 H:tensor([0.7498, 0.8848, 1.1414, 1.3271, 1.7694, 1.9044]) cost: 4496.944824\n","Epoch   82/300 H:tensor([0.7590, 0.8956, 1.1553, 1.3433, 1.7910, 1.9277]) cost: 4494.740723\n","Epoch   83/300 H:tensor([0.7681, 0.9065, 1.1693, 1.3596, 1.8127, 1.9510]) cost: 4492.538086\n","Epoch   84/300 H:tensor([0.7773, 0.9173, 1.1832, 1.3758, 1.8343, 1.9742]) cost: 4490.337402\n","Epoch   85/300 H:tensor([0.7865, 0.9281, 1.1971, 1.3920, 1.8559, 1.9975]) cost: 4488.137207\n","Epoch   86/300 H:tensor([0.7956, 0.9389, 1.2111, 1.4082, 1.8775, 2.0207]) cost: 4485.937988\n","Epoch   87/300 H:tensor([0.8048, 0.9497, 1.2250, 1.4244, 1.8990, 2.0439]) cost: 4483.740234\n","Epoch   88/300 H:tensor([0.8139, 0.9605, 1.2389, 1.4405, 1.9206, 2.0672]) cost: 4481.543457\n","Epoch   89/300 H:tensor([0.8231, 0.9713, 1.2528, 1.4567, 1.9422, 2.0904]) cost: 4479.347656\n","Epoch   90/300 H:tensor([0.8322, 0.9820, 1.2668, 1.4729, 1.9638, 2.1136]) cost: 4477.152832\n","Epoch   91/300 H:tensor([0.8413, 0.9928, 1.2807, 1.4891, 1.9854, 2.1368]) cost: 4474.959473\n","Epoch   92/300 H:tensor([0.8505, 1.0036, 1.2946, 1.5053, 2.0069, 2.1601]) cost: 4472.767090\n","Epoch   93/300 H:tensor([0.8596, 1.0144, 1.3085, 1.5214, 2.0285, 2.1833]) cost: 4470.576172\n","Epoch   94/300 H:tensor([0.8688, 1.0252, 1.3224, 1.5376, 2.0500, 2.2065]) cost: 4468.385742\n","Epoch   95/300 H:tensor([0.8779, 1.0360, 1.3363, 1.5538, 2.0716, 2.2296]) cost: 4466.196777\n","Epoch   96/300 H:tensor([0.8870, 1.0467, 1.3502, 1.5699, 2.0931, 2.2528]) cost: 4464.009277\n","Epoch   97/300 H:tensor([0.8962, 1.0575, 1.3641, 1.5861, 2.1147, 2.2760]) cost: 4461.821777\n","Epoch   98/300 H:tensor([0.9053, 1.0683, 1.3780, 1.6022, 2.1362, 2.2992]) cost: 4459.635742\n","Epoch   99/300 H:tensor([0.9144, 1.0790, 1.3919, 1.6184, 2.1577, 2.3224]) cost: 4457.451660\n","Epoch  100/300 H:tensor([0.9235, 1.0898, 1.4057, 1.6345, 2.1792, 2.3455]) cost: 4455.268066\n","Epoch  101/300 H:tensor([0.9326, 1.1006, 1.4196, 1.6507, 2.2008, 2.3687]) cost: 4453.085449\n","Epoch  102/300 H:tensor([0.9418, 1.1113, 1.4335, 1.6668, 2.2223, 2.3918]) cost: 4450.904785\n","Epoch  103/300 H:tensor([0.9509, 1.1221, 1.4474, 1.6829, 2.2438, 2.4150]) cost: 4448.724121\n","Epoch  104/300 H:tensor([0.9600, 1.1328, 1.4612, 1.6990, 2.2653, 2.4381]) cost: 4446.544434\n","Epoch  105/300 H:tensor([0.9691, 1.1436, 1.4751, 1.7152, 2.2868, 2.4612]) cost: 4444.366699\n","Epoch  106/300 H:tensor([0.9782, 1.1543, 1.4890, 1.7313, 2.3082, 2.4844]) cost: 4442.189941\n","Epoch  107/300 H:tensor([0.9873, 1.1651, 1.5028, 1.7474, 2.3297, 2.5075]) cost: 4440.014160\n","Epoch  108/300 H:tensor([0.9964, 1.1758, 1.5167, 1.7635, 2.3512, 2.5306]) cost: 4437.838867\n","Epoch  109/300 H:tensor([1.0055, 1.1866, 1.5305, 1.7796, 2.3727, 2.5537]) cost: 4435.665527\n","Epoch  110/300 H:tensor([1.0146, 1.1973, 1.5444, 1.7957, 2.3941, 2.5768]) cost: 4433.492676\n","Epoch  111/300 H:tensor([1.0237, 1.2080, 1.5582, 1.8118, 2.4156, 2.5999]) cost: 4431.321777\n","Epoch  112/300 H:tensor([1.0328, 1.2188, 1.5721, 1.8279, 2.4371, 2.6230]) cost: 4429.150879\n","Epoch  113/300 H:tensor([1.0419, 1.2295, 1.5859, 1.8440, 2.4585, 2.6461]) cost: 4426.981934\n","Epoch  114/300 H:tensor([1.0510, 1.2402, 1.5997, 1.8601, 2.4800, 2.6692]) cost: 4424.813965\n","Epoch  115/300 H:tensor([1.0601, 1.2509, 1.6136, 1.8762, 2.5014, 2.6923]) cost: 4422.646973\n","Epoch  116/300 H:tensor([1.0692, 1.2617, 1.6274, 1.8922, 2.5228, 2.7153]) cost: 4420.479980\n","Epoch  117/300 H:tensor([1.0782, 1.2724, 1.6412, 1.9083, 2.5443, 2.7384]) cost: 4418.315430\n","Epoch  118/300 H:tensor([1.0873, 1.2831, 1.6550, 1.9244, 2.5657, 2.7614]) cost: 4416.151855\n","Epoch  119/300 H:tensor([1.0964, 1.2938, 1.6689, 1.9404, 2.5871, 2.7845]) cost: 4413.989258\n","Epoch  120/300 H:tensor([1.1055, 1.3045, 1.6827, 1.9565, 2.6085, 2.8075]) cost: 4411.827637\n","Epoch  121/300 H:tensor([1.1145, 1.3152, 1.6965, 1.9726, 2.6299, 2.8306]) cost: 4409.666992\n","Epoch  122/300 H:tensor([1.1236, 1.3259, 1.7103, 1.9886, 2.6513, 2.8536]) cost: 4407.507324\n","Epoch  123/300 H:tensor([1.1327, 1.3366, 1.7241, 2.0047, 2.6727, 2.8766]) cost: 4405.349121\n","Epoch  124/300 H:tensor([1.1418, 1.3473, 1.7379, 2.0207, 2.6941, 2.8997]) cost: 4403.191895\n","Epoch  125/300 H:tensor([1.1508, 1.3580, 1.7517, 2.0368, 2.7155, 2.9227]) cost: 4401.035645\n","Epoch  126/300 H:tensor([1.1599, 1.3687, 1.7655, 2.0528, 2.7369, 2.9457]) cost: 4398.880859\n","Epoch  127/300 H:tensor([1.1689, 1.3794, 1.7793, 2.0688, 2.7582, 2.9687]) cost: 4396.726074\n","Epoch  128/300 H:tensor([1.1780, 1.3901, 1.7930, 2.0849, 2.7796, 2.9917]) cost: 4394.573730\n","Epoch  129/300 H:tensor([1.1871, 1.4008, 1.8068, 2.1009, 2.8010, 3.0147]) cost: 4392.421875\n","Epoch  130/300 H:tensor([1.1961, 1.4115, 1.8206, 2.1169, 2.8223, 3.0377]) cost: 4390.270996\n","Epoch  131/300 H:tensor([1.2052, 1.4221, 1.8344, 2.1329, 2.8437, 3.0607]) cost: 4388.121582\n","Epoch  132/300 H:tensor([1.2142, 1.4328, 1.8482, 2.1489, 2.8650, 3.0836]) cost: 4385.972656\n","Epoch  133/300 H:tensor([1.2233, 1.4435, 1.8619, 2.1649, 2.8864, 3.1066]) cost: 4383.824707\n","Epoch  134/300 H:tensor([1.2323, 1.4542, 1.8757, 2.1809, 2.9077, 3.1296]) cost: 4381.678711\n","Epoch  135/300 H:tensor([1.2413, 1.4648, 1.8895, 2.1969, 2.9290, 3.1525]) cost: 4379.533691\n","Epoch  136/300 H:tensor([1.2504, 1.4755, 1.9032, 2.2129, 2.9504, 3.1755]) cost: 4377.389160\n","Epoch  137/300 H:tensor([1.2594, 1.4862, 1.9170, 2.2289, 2.9717, 3.1984]) cost: 4375.246094\n","Epoch  138/300 H:tensor([1.2685, 1.4968, 1.9307, 2.2449, 2.9930, 3.2214]) cost: 4373.104004\n","Epoch  139/300 H:tensor([1.2775, 1.5075, 1.9445, 2.2609, 3.0143, 3.2443]) cost: 4370.962891\n","Epoch  140/300 H:tensor([1.2865, 1.5182, 1.9582, 2.2769, 3.0356, 3.2672]) cost: 4368.822754\n","Epoch  141/300 H:tensor([1.2955, 1.5288, 1.9719, 2.2929, 3.0569, 3.2902]) cost: 4366.684082\n","Epoch  142/300 H:tensor([1.3046, 1.5395, 1.9857, 2.3088, 3.0782, 3.3131]) cost: 4364.546387\n","Epoch  143/300 H:tensor([1.3136, 1.5501, 1.9994, 2.3248, 3.0995, 3.3360]) cost: 4362.409668\n","Epoch  144/300 H:tensor([1.3226, 1.5608, 2.0131, 2.3408, 3.1208, 3.3589]) cost: 4360.273926\n","Epoch  145/300 H:tensor([1.3316, 1.5714, 2.0269, 2.3567, 3.1420, 3.3818]) cost: 4358.139648\n","Epoch  146/300 H:tensor([1.3407, 1.5820, 2.0406, 2.3727, 3.1633, 3.4047]) cost: 4356.005859\n","Epoch  147/300 H:tensor([1.3497, 1.5927, 2.0543, 2.3886, 3.1846, 3.4276]) cost: 4353.874512\n","Epoch  148/300 H:tensor([1.3587, 1.6033, 2.0680, 2.4046, 3.2058, 3.4505]) cost: 4351.742676\n","Epoch  149/300 H:tensor([1.3677, 1.6139, 2.0817, 2.4205, 3.2271, 3.4733]) cost: 4349.611816\n","Epoch  150/300 H:tensor([1.3767, 1.6246, 2.0955, 2.4365, 3.2483, 3.4962]) cost: 4347.482910\n","Epoch  151/300 H:tensor([1.3857, 1.6352, 2.1092, 2.4524, 3.2696, 3.5191]) cost: 4345.354980\n","Epoch  152/300 H:tensor([1.3947, 1.6458, 2.1229, 2.4683, 3.2908, 3.5419]) cost: 4343.227539\n","Epoch  153/300 H:tensor([1.4037, 1.6565, 2.1366, 2.4843, 3.3121, 3.5648]) cost: 4341.101562\n","Epoch  154/300 H:tensor([1.4127, 1.6671, 2.1503, 2.5002, 3.3333, 3.5876]) cost: 4338.977051\n","Epoch  155/300 H:tensor([1.4217, 1.6777, 2.1639, 2.5161, 3.3545, 3.6105]) cost: 4336.853027\n","Epoch  156/300 H:tensor([1.4307, 1.6883, 2.1776, 2.5320, 3.3757, 3.6333]) cost: 4334.730469\n","Epoch  157/300 H:tensor([1.4397, 1.6989, 2.1913, 2.5479, 3.3969, 3.6562]) cost: 4332.608887\n","Epoch  158/300 H:tensor([1.4487, 1.7095, 2.2050, 2.5638, 3.4181, 3.6790]) cost: 4330.487793\n","Epoch  159/300 H:tensor([1.4577, 1.7201, 2.2187, 2.5797, 3.4393, 3.7018]) cost: 4328.368652\n","Epoch  160/300 H:tensor([1.4667, 1.7307, 2.2324, 2.5956, 3.4605, 3.7246]) cost: 4326.250000\n","Epoch  161/300 H:tensor([1.4756, 1.7413, 2.2460, 2.6115, 3.4817, 3.7474]) cost: 4324.132324\n","Epoch  162/300 H:tensor([1.4846, 1.7519, 2.2597, 2.6274, 3.5029, 3.7702]) cost: 4322.016113\n","Epoch  163/300 H:tensor([1.4936, 1.7625, 2.2734, 2.6433, 3.5241, 3.7930]) cost: 4319.900879\n","Epoch  164/300 H:tensor([1.5026, 1.7731, 2.2870, 2.6592, 3.5453, 3.8158]) cost: 4317.787109\n","Epoch  165/300 H:tensor([1.5116, 1.7837, 2.3007, 2.6751, 3.5664, 3.8386]) cost: 4315.674316\n","Epoch  166/300 H:tensor([1.5205, 1.7943, 2.3143, 2.6910, 3.5876, 3.8614]) cost: 4313.562012\n","Epoch  167/300 H:tensor([1.5295, 1.8049, 2.3280, 2.7068, 3.6088, 3.8842]) cost: 4311.450684\n","Epoch  168/300 H:tensor([1.5385, 1.8155, 2.3416, 2.7227, 3.6299, 3.9069]) cost: 4309.341309\n","Epoch  169/300 H:tensor([1.5474, 1.8260, 2.3553, 2.7386, 3.6511, 3.9297]) cost: 4307.231934\n","Epoch  170/300 H:tensor([1.5564, 1.8366, 2.3689, 2.7544, 3.6722, 3.9524]) cost: 4305.124023\n","Epoch  171/300 H:tensor([1.5654, 1.8472, 2.3826, 2.7703, 3.6933, 3.9752]) cost: 4303.017578\n","Epoch  172/300 H:tensor([1.5743, 1.8578, 2.3962, 2.7861, 3.7145, 3.9979]) cost: 4300.912109\n","Epoch  173/300 H:tensor([1.5833, 1.8683, 2.4098, 2.8020, 3.7356, 4.0207]) cost: 4298.806641\n","Epoch  174/300 H:tensor([1.5922, 1.8789, 2.4234, 2.8178, 3.7567, 4.0434]) cost: 4296.704102\n","Epoch  175/300 H:tensor([1.6012, 1.8895, 2.4371, 2.8337, 3.7778, 4.0661]) cost: 4294.601074\n","Epoch  176/300 H:tensor([1.6101, 1.9000, 2.4507, 2.8495, 3.7989, 4.0889]) cost: 4292.500000\n","Epoch  177/300 H:tensor([1.6191, 1.9106, 2.4643, 2.8653, 3.8200, 4.1116]) cost: 4290.398926\n","Epoch  178/300 H:tensor([1.6280, 1.9211, 2.4779, 2.8811, 3.8411, 4.1343]) cost: 4288.300293\n","Epoch  179/300 H:tensor([1.6370, 1.9317, 2.4915, 2.8970, 3.8622, 4.1570]) cost: 4286.201660\n","Epoch  180/300 H:tensor([1.6459, 1.9423, 2.5051, 2.9128, 3.8833, 4.1797]) cost: 4284.104492\n","Epoch  181/300 H:tensor([1.6548, 1.9528, 2.5187, 2.9286, 3.9044, 4.2024]) cost: 4282.008301\n","Epoch  182/300 H:tensor([1.6638, 1.9633, 2.5323, 2.9444, 3.9255, 4.2251]) cost: 4279.913574\n","Epoch  183/300 H:tensor([1.6727, 1.9739, 2.5459, 2.9602, 3.9466, 4.2477]) cost: 4277.819824\n","Epoch  184/300 H:tensor([1.6816, 1.9844, 2.5595, 2.9760, 3.9676, 4.2704]) cost: 4275.726074\n","Epoch  185/300 H:tensor([1.6906, 1.9950, 2.5731, 2.9918, 3.9887, 4.2931]) cost: 4273.634766\n","Epoch  186/300 H:tensor([1.6995, 2.0055, 2.5867, 3.0076, 4.0098, 4.3158]) cost: 4271.543457\n","Epoch  187/300 H:tensor([1.7084, 2.0160, 2.6003, 3.0234, 4.0308, 4.3384]) cost: 4269.453613\n","Epoch  188/300 H:tensor([1.7173, 2.0266, 2.6139, 3.0392, 4.0518, 4.3611]) cost: 4267.365234\n","Epoch  189/300 H:tensor([1.7263, 2.0371, 2.6274, 3.0550, 4.0729, 4.3837]) cost: 4265.277344\n","Epoch  190/300 H:tensor([1.7352, 2.0476, 2.6410, 3.0708, 4.0939, 4.4064]) cost: 4263.190918\n","Epoch  191/300 H:tensor([1.7441, 2.0581, 2.6546, 3.0865, 4.1150, 4.4290]) cost: 4261.105469\n","Epoch  192/300 H:tensor([1.7530, 2.0687, 2.6681, 3.1023, 4.1360, 4.4516]) cost: 4259.020996\n","Epoch  193/300 H:tensor([1.7619, 2.0792, 2.6817, 3.1181, 4.1570, 4.4742]) cost: 4256.937012\n","Epoch  194/300 H:tensor([1.7708, 2.0897, 2.6953, 3.1339, 4.1780, 4.4969]) cost: 4254.854980\n","Epoch  195/300 H:tensor([1.7797, 2.1002, 2.7088, 3.1496, 4.1990, 4.5195]) cost: 4252.772949\n","Epoch  196/300 H:tensor([1.7886, 2.1107, 2.7224, 3.1654, 4.2200, 4.5421]) cost: 4250.692871\n","Epoch  197/300 H:tensor([1.7976, 2.1212, 2.7359, 3.1811, 4.2410, 4.5647]) cost: 4248.613281\n","Epoch  198/300 H:tensor([1.8065, 2.1317, 2.7495, 3.1969, 4.2620, 4.5873]) cost: 4246.535645\n","Epoch  199/300 H:tensor([1.8154, 2.1422, 2.7630, 3.2126, 4.2830, 4.6099]) cost: 4244.458496\n","Epoch  200/300 H:tensor([1.8242, 2.1527, 2.7765, 3.2284, 4.3040, 4.6325]) cost: 4242.382324\n","Epoch  201/300 H:tensor([1.8331, 2.1632, 2.7901, 3.2441, 4.3250, 4.6550]) cost: 4240.307129\n","Epoch  202/300 H:tensor([1.8420, 2.1737, 2.8036, 3.2598, 4.3459, 4.6776]) cost: 4238.233398\n","Epoch  203/300 H:tensor([1.8509, 2.1842, 2.8171, 3.2755, 4.3669, 4.7002]) cost: 4236.160156\n","Epoch  204/300 H:tensor([1.8598, 2.1947, 2.8307, 3.2913, 4.3879, 4.7227]) cost: 4234.087891\n","Epoch  205/300 H:tensor([1.8687, 2.2052, 2.8442, 3.3070, 4.4088, 4.7453]) cost: 4232.017090\n","Epoch  206/300 H:tensor([1.8776, 2.2157, 2.8577, 3.3227, 4.4298, 4.7678]) cost: 4229.947266\n","Epoch  207/300 H:tensor([1.8865, 2.2261, 2.8712, 3.3384, 4.4507, 4.7904]) cost: 4227.878418\n","Epoch  208/300 H:tensor([1.8953, 2.2366, 2.8847, 3.3541, 4.4717, 4.8129]) cost: 4225.810547\n","Epoch  209/300 H:tensor([1.9042, 2.2471, 2.8982, 3.3698, 4.4926, 4.8355]) cost: 4223.744141\n","Epoch  210/300 H:tensor([1.9131, 2.2576, 2.9117, 3.3855, 4.5135, 4.8580]) cost: 4221.677734\n","Epoch  211/300 H:tensor([1.9220, 2.2680, 2.9252, 3.4012, 4.5344, 4.8805]) cost: 4219.613770\n","Epoch  212/300 H:tensor([1.9308, 2.2785, 2.9387, 3.4169, 4.5554, 4.9030]) cost: 4217.549805\n","Epoch  213/300 H:tensor([1.9397, 2.2890, 2.9522, 3.4326, 4.5763, 4.9255]) cost: 4215.487305\n","Epoch  214/300 H:tensor([1.9486, 2.2994, 2.9657, 3.4483, 4.5972, 4.9480]) cost: 4213.425781\n","Epoch  215/300 H:tensor([1.9574, 2.3099, 2.9792, 3.4640, 4.6181, 4.9705]) cost: 4211.365234\n","Epoch  216/300 H:tensor([1.9663, 2.3203, 2.9927, 3.4797, 4.6390, 4.9930]) cost: 4209.305664\n","Epoch  217/300 H:tensor([1.9751, 2.3308, 3.0062, 3.4953, 4.6599, 5.0155]) cost: 4207.247070\n","Epoch  218/300 H:tensor([1.9840, 2.3412, 3.0196, 3.5110, 4.6808, 5.0380]) cost: 4205.189941\n","Epoch  219/300 H:tensor([1.9929, 2.3517, 3.0331, 3.5267, 4.7016, 5.0605]) cost: 4203.133301\n","Epoch  220/300 H:tensor([2.0017, 2.3621, 3.0466, 3.5423, 4.7225, 5.0829]) cost: 4201.078125\n","Epoch  221/300 H:tensor([2.0106, 2.3726, 3.0600, 3.5580, 4.7434, 5.1054]) cost: 4199.023926\n","Epoch  222/300 H:tensor([2.0194, 2.3830, 3.0735, 3.5736, 4.7643, 5.1279]) cost: 4196.971191\n","Epoch  223/300 H:tensor([2.0282, 2.3935, 3.0870, 3.5893, 4.7851, 5.1503]) cost: 4194.918457\n","Epoch  224/300 H:tensor([2.0371, 2.4039, 3.1004, 3.6049, 4.8060, 5.1728]) cost: 4192.867188\n","Epoch  225/300 H:tensor([2.0459, 2.4143, 3.1139, 3.6206, 4.8268, 5.1952]) cost: 4190.817383\n","Epoch  226/300 H:tensor([2.0548, 2.4248, 3.1273, 3.6362, 4.8477, 5.2176]) cost: 4188.768066\n","Epoch  227/300 H:tensor([2.0636, 2.4352, 3.1408, 3.6518, 4.8685, 5.2401]) cost: 4186.720215\n","Epoch  228/300 H:tensor([2.0724, 2.4456, 3.1542, 3.6675, 4.8893, 5.2625]) cost: 4184.673340\n","Epoch  229/300 H:tensor([2.0813, 2.4560, 3.1677, 3.6831, 4.9102, 5.2849]) cost: 4182.627441\n","Epoch  230/300 H:tensor([2.0901, 2.4665, 3.1811, 3.6987, 4.9310, 5.3073]) cost: 4180.582031\n","Epoch  231/300 H:tensor([2.0989, 2.4769, 3.1945, 3.7143, 4.9518, 5.3297]) cost: 4178.537598\n","Epoch  232/300 H:tensor([2.1078, 2.4873, 3.2080, 3.7299, 4.9726, 5.3521]) cost: 4176.495605\n","Epoch  233/300 H:tensor([2.1166, 2.4977, 3.2214, 3.7456, 4.9934, 5.3745]) cost: 4174.453613\n","Epoch  234/300 H:tensor([2.1254, 2.5081, 3.2348, 3.7612, 5.0142, 5.3969]) cost: 4172.412109\n","Epoch  235/300 H:tensor([2.1342, 2.5185, 3.2482, 3.7768, 5.0350, 5.4193]) cost: 4170.373047\n","Epoch  236/300 H:tensor([2.1430, 2.5289, 3.2616, 3.7924, 5.0558, 5.4417]) cost: 4168.333984\n","Epoch  237/300 H:tensor([2.1518, 2.5393, 3.2750, 3.8080, 5.0766, 5.4641]) cost: 4166.296387\n","Epoch  238/300 H:tensor([2.1607, 2.5497, 3.2885, 3.8236, 5.0974, 5.4864]) cost: 4164.259277\n","Epoch  239/300 H:tensor([2.1695, 2.5601, 3.3019, 3.8391, 5.1182, 5.5088]) cost: 4162.223633\n","Epoch  240/300 H:tensor([2.1783, 2.5705, 3.3153, 3.8547, 5.1389, 5.5312]) cost: 4160.188965\n","Epoch  241/300 H:tensor([2.1871, 2.5809, 3.3287, 3.8703, 5.1597, 5.5535]) cost: 4158.154785\n","Epoch  242/300 H:tensor([2.1959, 2.5913, 3.3421, 3.8859, 5.1805, 5.5759]) cost: 4156.122559\n","Epoch  243/300 H:tensor([2.2047, 2.6017, 3.3554, 3.9014, 5.2012, 5.5982]) cost: 4154.091309\n","Epoch  244/300 H:tensor([2.2135, 2.6121, 3.3688, 3.9170, 5.2220, 5.6205]) cost: 4152.060547\n","Epoch  245/300 H:tensor([2.2223, 2.6224, 3.3822, 3.9326, 5.2427, 5.6429]) cost: 4150.031250\n","Epoch  246/300 H:tensor([2.2311, 2.6328, 3.3956, 3.9481, 5.2634, 5.6652]) cost: 4148.002441\n","Epoch  247/300 H:tensor([2.2399, 2.6432, 3.4090, 3.9637, 5.2842, 5.6875]) cost: 4145.975098\n","Epoch  248/300 H:tensor([2.2487, 2.6536, 3.4224, 3.9792, 5.3049, 5.7098]) cost: 4143.948730\n","Epoch  249/300 H:tensor([2.2574, 2.6639, 3.4357, 3.9948, 5.3256, 5.7321]) cost: 4141.923340\n","Epoch  250/300 H:tensor([2.2662, 2.6743, 3.4491, 4.0103, 5.3463, 5.7544]) cost: 4139.898926\n","Epoch  251/300 H:tensor([2.2750, 2.6847, 3.4625, 4.0259, 5.3671, 5.7767]) cost: 4137.875000\n","Epoch  252/300 H:tensor([2.2838, 2.6950, 3.4758, 4.0414, 5.3878, 5.7990]) cost: 4135.853027\n","Epoch  253/300 H:tensor([2.2926, 2.7054, 3.4892, 4.0569, 5.4085, 5.8213]) cost: 4133.831543\n","Epoch  254/300 H:tensor([2.3014, 2.7157, 3.5025, 4.0725, 5.4292, 5.8436]) cost: 4131.811035\n","Epoch  255/300 H:tensor([2.3101, 2.7261, 3.5159, 4.0880, 5.4499, 5.8658]) cost: 4129.791504\n","Epoch  256/300 H:tensor([2.3189, 2.7365, 3.5292, 4.1035, 5.4705, 5.8881]) cost: 4127.773438\n","Epoch  257/300 H:tensor([2.3277, 2.7468, 3.5426, 4.1190, 5.4912, 5.9104]) cost: 4125.755859\n","Epoch  258/300 H:tensor([2.3364, 2.7572, 3.5559, 4.1345, 5.5119, 5.9326]) cost: 4123.739746\n","Epoch  259/300 H:tensor([2.3452, 2.7675, 3.5693, 4.1500, 5.5326, 5.9549]) cost: 4121.724121\n","Epoch  260/300 H:tensor([2.3540, 2.7778, 3.5826, 4.1655, 5.5532, 5.9771]) cost: 4119.709961\n","Epoch  261/300 H:tensor([2.3627, 2.7882, 3.5959, 4.1810, 5.5739, 5.9994]) cost: 4117.696777\n","Epoch  262/300 H:tensor([2.3715, 2.7985, 3.6093, 4.1965, 5.5946, 6.0216]) cost: 4115.684570\n","Epoch  263/300 H:tensor([2.3803, 2.8089, 3.6226, 4.2120, 5.6152, 6.0438]) cost: 4113.673340\n","Epoch  264/300 H:tensor([2.3890, 2.8192, 3.6359, 4.2275, 5.6359, 6.0660]) cost: 4111.663574\n","Epoch  265/300 H:tensor([2.3978, 2.8295, 3.6492, 4.2430, 5.6565, 6.0882]) cost: 4109.653809\n","Epoch  266/300 H:tensor([2.4065, 2.8398, 3.6625, 4.2585, 5.6771, 6.1105]) cost: 4107.645996\n","Epoch  267/300 H:tensor([2.4153, 2.8502, 3.6758, 4.2740, 5.6978, 6.1327]) cost: 4105.639160\n","Epoch  268/300 H:tensor([2.4240, 2.8605, 3.6892, 4.2894, 5.7184, 6.1549]) cost: 4103.632812\n","Epoch  269/300 H:tensor([2.4327, 2.8708, 3.7025, 4.3049, 5.7390, 6.1771]) cost: 4101.627441\n","Epoch  270/300 H:tensor([2.4415, 2.8811, 3.7158, 4.3204, 5.7596, 6.1992]) cost: 4099.623535\n","Epoch  271/300 H:tensor([2.4502, 2.8914, 3.7291, 4.3358, 5.7802, 6.2214]) cost: 4097.620117\n","Epoch  272/300 H:tensor([2.4590, 2.9017, 3.7424, 4.3513, 5.8008, 6.2436]) cost: 4095.617920\n","Epoch  273/300 H:tensor([2.4677, 2.9121, 3.7556, 4.3667, 5.8214, 6.2658]) cost: 4093.617188\n","Epoch  274/300 H:tensor([2.4764, 2.9224, 3.7689, 4.3822, 5.8420, 6.2879]) cost: 4091.616943\n","Epoch  275/300 H:tensor([2.4852, 2.9327, 3.7822, 4.3976, 5.8626, 6.3101]) cost: 4089.618164\n","Epoch  276/300 H:tensor([2.4939, 2.9430, 3.7955, 4.4131, 5.8832, 6.3323]) cost: 4087.619873\n","Epoch  277/300 H:tensor([2.5026, 2.9533, 3.8088, 4.4285, 5.9038, 6.3544]) cost: 4085.623047\n","Epoch  278/300 H:tensor([2.5113, 2.9636, 3.8221, 4.4439, 5.9243, 6.3765]) cost: 4083.626709\n","Epoch  279/300 H:tensor([2.5201, 2.9739, 3.8353, 4.4594, 5.9449, 6.3987]) cost: 4081.631836\n","Epoch  280/300 H:tensor([2.5288, 2.9841, 3.8486, 4.4748, 5.9655, 6.4208]) cost: 4079.637451\n","Epoch  281/300 H:tensor([2.5375, 2.9944, 3.8619, 4.4902, 5.9860, 6.4429]) cost: 4077.644531\n","Epoch  282/300 H:tensor([2.5462, 3.0047, 3.8751, 4.5056, 6.0066, 6.4651]) cost: 4075.652588\n","Epoch  283/300 H:tensor([2.5549, 3.0150, 3.8884, 4.5211, 6.0271, 6.4872]) cost: 4073.661865\n","Epoch  284/300 H:tensor([2.5636, 3.0253, 3.9016, 4.5365, 6.0477, 6.5093]) cost: 4071.671631\n","Epoch  285/300 H:tensor([2.5724, 3.0356, 3.9149, 4.5519, 6.0682, 6.5314]) cost: 4069.682373\n","Epoch  286/300 H:tensor([2.5811, 3.0458, 3.9281, 4.5673, 6.0887, 6.5535]) cost: 4067.694336\n","Epoch  287/300 H:tensor([2.5898, 3.0561, 3.9414, 4.5827, 6.1092, 6.5756]) cost: 4065.707275\n","Epoch  288/300 H:tensor([2.5985, 3.0664, 3.9546, 4.5981, 6.1298, 6.5977]) cost: 4063.721436\n","Epoch  289/300 H:tensor([2.6072, 3.0766, 3.9679, 4.6135, 6.1503, 6.6198]) cost: 4061.736328\n","Epoch  290/300 H:tensor([2.6159, 3.0869, 3.9811, 4.6288, 6.1708, 6.6418]) cost: 4059.752686\n","Epoch  291/300 H:tensor([2.6246, 3.0972, 3.9943, 4.6442, 6.1913, 6.6639]) cost: 4057.769531\n","Epoch  292/300 H:tensor([2.6333, 3.1074, 4.0075, 4.6596, 6.2118, 6.6860]) cost: 4055.787109\n","Epoch  293/300 H:tensor([2.6420, 3.1177, 4.0208, 4.6750, 6.2323, 6.7080]) cost: 4053.806396\n","Epoch  294/300 H:tensor([2.6506, 3.1279, 4.0340, 4.6904, 6.2528, 6.7301]) cost: 4051.826416\n","Epoch  295/300 H:tensor([2.6593, 3.1382, 4.0472, 4.7057, 6.2733, 6.7521]) cost: 4049.847412\n","Epoch  296/300 H:tensor([2.6680, 3.1484, 4.0604, 4.7211, 6.2937, 6.7742]) cost: 4047.869141\n","Epoch  297/300 H:tensor([2.6767, 3.1587, 4.0736, 4.7365, 6.3142, 6.7962]) cost: 4045.892578\n","Epoch  298/300 H:tensor([2.6854, 3.1689, 4.0868, 4.7518, 6.3347, 6.8182]) cost: 4043.916016\n","Epoch  299/300 H:tensor([2.6941, 3.1792, 4.1000, 4.7672, 6.3551, 6.8403]) cost: 4041.941406\n","Epoch  300/300 H:tensor([2.7027, 3.1894, 4.1133, 4.7825, 6.3756, 6.8623]) cost: 4039.967529\n"]}]}]}